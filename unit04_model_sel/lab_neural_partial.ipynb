{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEX6egMQJBRY"
      },
      "source": [
        "# Lab:  Model Order Selection for Neural Data\n",
        "\n",
        "Machine learning is a key tool for neuroscientists to understand how sensory and motor signals are encoded in the brain.  In addition to improving our scientific understanding of neural phenomena, understanding neural encoding is critical for brain machine interfaces.  In this lab, you will use model selection for performing some simple analysis on real neural signals.  \n",
        "\n",
        "Before doing this lab, you should review the ideas in the [polynomial model selection demo](./polyfit.ipynb).  In addition to the concepts in that demo, you will learn to:\n",
        "* Represent neural time-series data in arrays\n",
        "* Load data from a pickle file\n",
        "* Describe and fit memoryless linear models\n",
        "* Describe and fit linear time-series models with delays\n",
        "* Fit linear models with multiple target outputs\n",
        "* Select the optimal delay via cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0tHW_lbJBRZ"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "The data in this lab comes from neural recordings described in:\n",
        "\n",
        "<a href=\"http://jn.physiology.org/content/106/2/764.short\">\n",
        "Stevenson, Ian H., et al. \"Statistical assessment of the stability of neural movement representations.\" Journal of neurophysiology 106.2 (2011): 764-774</a>\n",
        "\n",
        "Neurons are the basic information processing units in the brain.  Neurons communicate with one another via *spikes* or *action potentials* which are brief events where voltage in the neuron rapidly rises then falls.  These spikes trigger the electro-chemical signals between one neuron and another.  In this experiment, the spikes were recorded from 196 neurons in the primary motor cortex (M1) of a monkey using an electrode array implanted onto the surface of a monkey's brain.  During the recording, the monkey performed several reaching tasks and the position and velocity of the hand was recorded as well.  \n",
        "\n",
        "The goal of the experiment is to try to *read the monkey's brain*:  That is, predict the hand motion from the neural signals from the motor cortex.\n",
        "\n",
        "We first load the key packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHhGb6ORJBRa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42Cc0hdhJBRa"
      },
      "source": [
        "The full data is available on the CRCNS website  http://crcns.org/data-sets/movements/dream.  This website has a large number of great datasets and can be used for projects as well.  However, the raw data files can be quite large.  To make the lab easier, the [Kording lab](http://kordinglab.com/) at UPenn has put together an excellent [repository](https://github.com/KordingLab/Neural_Decoding) where they have created simple pre-processed versions of the data.  You can download the file `example_data_s1.pickle` from the [Dropbox link](https://www.dropbox.com/sh/n4924ipcfjqc0t6/AADOv9JYMUBK1tlg9P71gSSra/example_data_s1.pickle?dl=0).  Alternatively, you can directly run the following code.  This may take a little while to download since the file is 26 MB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpXQRXTLJBRa"
      },
      "outputs": [],
      "source": [
        "fn_src = 'https://www.dropbox.com/sh/n4924ipcfjqc0t6/AADOv9JYMUBK1tlg9P71gSSra/example_data_s1.pickle?dl=1'\n",
        "fn_dst = 'example_data_s1.pickle'\n",
        "\n",
        "import os\n",
        "from six.moves import urllib\n",
        "\n",
        "if os.path.isfile(fn_dst):\n",
        "    print('File %s is already downloaded' % fn_dst)\n",
        "else:\n",
        "    urllib.request.urlretrieve(fn_src, fn_dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnY7Kf_aJBRa"
      },
      "source": [
        "The file is a *pickle* data structure, which is a package to serialize python objects into data files.  Once you have downloaded the file, you can run the following command to retrieve the data from the pickle file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWx0DJU2JBRb"
      },
      "outputs": [],
      "source": [
        "with open('example_data_s1.pickle', 'rb') as fp:\n",
        "    X,y = pickle.load(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpLVIMnYJBRb"
      },
      "source": [
        "The matrix `X` is matrix of spike counts where `X[i,j]` is the number of spikes from neuron `j` in time bin `i`.\n",
        "The matrix `y` has two columns:\n",
        "* `y[i,0] = ` velocity of the monkey's hand in the x-direction\n",
        "* `y[i,1] = ` velocity of the monkey's hand in the y-direction\n",
        "Our goal will be to predict `y` from `X`.  \n",
        "\n",
        "Each time bin represent `tsamp=0.05` seconds of time.  Using `X.shape` and `y.shape` compute and print:\n",
        "* `nt = ` the total number of time bins\n",
        "* `nneuron = ` the total number of neurons\n",
        "* `nout = ` the total number of output variables to track = number of columns in `y`\n",
        "* `ttotal = ` total time of the experiment is seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poliG4SiJBRb"
      },
      "outputs": [],
      "source": [
        "tsamp = 0.05   # sampling time in seconds\n",
        "\n",
        "# TODO\n",
        "nt = X.shape[0]            # number of time bins\n",
        "nneurons = X.shape[1]      # number of neurons\n",
        "nout = y.shape[1]          # number of output variables\n",
        "ttotal = nt * tsamp        # total time in seconds\n",
        "\n",
        "print(\"nt =\", nt)\n",
        "print(\"nneurons =\", nneurons)\n",
        "print(\"nout =\", nout)\n",
        "print(\"ttotal =\", ttotal, \"seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMw5w10RJBRb"
      },
      "source": [
        "## Fitting a Memoryless Linear Model\n",
        "\n",
        "Let's first try a simple linear regression model to fit the data.\n",
        "\n",
        "First, use the `train_test_split` function to split the data into training and test.  Let `Xtr,ytr` be the training data set and `Xts,yts` be the test data set.  Use `test_size=0.33` so `1/3` of the data is used for test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsGtzcm9JBRb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TODO\n",
        "Xtr, Xts, ytr, yts = train_test_split(X, y, test_size=0.33, random_state=0)\n",
        "\n",
        "print(\"Training set:\", Xtr.shape, ytr.shape)\n",
        "print(\"Test set:\", Xts.shape, yts.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1pqhnjrJBRb"
      },
      "source": [
        "Now, fit a linear model using `Xtr,ytr`.  Make a prediction  `yhat` using `Xts`.  Compare `yhat` to `yts` to measure `rsq`, the  `R^2`.  You can use the `r2_score` method. Print the `rsq` value.  You should get `rsq` of around `0.45`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS5dhClzJBRc"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Fit linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(Xtr, ytr)\n",
        "\n",
        "# TODO\n",
        "yhat = model.predict(Xts)          # predictions on test set\n",
        "rsq = r2_score(yts, yhat)          # R^2 score\n",
        "\n",
        "print(\"R^2 =\", rsq)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdhxxF52JBRc"
      },
      "source": [
        "It is useful to plot the predicted vs. true values.  Since we have two outputs, create two `subplots` using the `plt.subplot()` command.  In plot `i=0,1`, plot `yhat[:,i]` vs. `yts[:,i]` with a scatter plot.   Label the axes of the plots.  You may also use the command:\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    \n",
        "to make the figures a little larger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM-rpYQ2JBRc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "for i in range(y.shape[1]):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.scatter(yts[:, i], yhat[:, i], alpha=0.5)\n",
        "    plt.xlabel(\"True y{}\".format(i))\n",
        "    plt.ylabel(\"Predicted y{}\".format(i))\n",
        "    plt.plot([yts[:, i].min(), yts[:, i].max()],\n",
        "             [yts[:, i].min(), yts[:, i].max()],\n",
        "             'r--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHZ2XQIBJBRc"
      },
      "source": [
        "## Fitting Models with Delay\n",
        "\n",
        "One way we can improve the model accuracy is to used delayed version of the features.  Specifically, the model we used above mapped the features\n",
        "\n",
        "    yhat[i,k] = \\sum_{j=0}^{p-1} X[i,j]*w[j,k] + b[k]\n",
        "    \n",
        "where `p` is the number of features and `w[j,k]` is a matrix of coefficients.  In this model,  `yhat[i,:]` at time `i` was only dependent on the inputs  `X[i,:]` at time `i`.  In signal processing, this is called a *memoryless* model.  However, in many physical systems, such as those that arise in neuroscience, there is a delay between the inputs `X[i,:]` and the outputs `y[i]`.  For such cases, we can use a model of the form,\n",
        "\n",
        "    yhat[i+d,k] = \\sum_{j=0}^{p-1} \\sum_{m=0}^d X[i+m,j]*W[j,m,k] + b[k]\n",
        "    \n",
        "where `W` is a 3-dim array of coefficients where:\n",
        "\n",
        "    W[j,m,k] is the influence of the input X[i+m,j] onto output y[i+d,k]\n",
        "\n",
        "\n",
        "In signal processing, this model is called an *FIR* filter and `W[j,:,k]` is the *impulse response* from the `j`-th input to the `k`-th output.  The point is that the output at time `i+d` depends on the inputs at times `i,i+1,...,i+d`.  Hence, it depends on the last `d+1` time steps, not just the most recent time.\n",
        "\n",
        "To translate this into a linear regression problem, complete the following function that creates a new feature and target matrix where:\n",
        "\n",
        "    Xdly[i,:] has the rows X[i,:], X[i++1,:], ..., X[i+dly,:]\n",
        "    ydly[i,:] = y[i+dly,:]\n",
        "    \n",
        "Thus, `Xdly[i,:]` contains all the delayed fetaures for the target `yhat`.  Note that if `X` is `n x p` then `Xdly` will be `n-dly x (dly+1)*p`.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UelOeKt4JBRc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_dly_data(X, y, dly):\n",
        "    \"\"\"\n",
        "    Create delayed data\n",
        "    X: (n, p) input features\n",
        "    y: (n, q) output\n",
        "    dly: number of delays\n",
        "    \"\"\"\n",
        "    nt, p = X.shape\n",
        "\n",
        "    # 构造延迟特征\n",
        "    Xdly = np.zeros((nt - dly, p * (dly + 1)))\n",
        "    for i in range(dly, nt):\n",
        "        Xdly[i - dly, :] = X[i - dly:i + 1, :].flatten(order='F')\n",
        "        # order='F' 保证是按时间步拼接（X[i-dly], ..., X[i]）\n",
        "\n",
        "    # 构造目标：从 dly 开始\n",
        "    ydly = y[dly:,:]\n",
        "\n",
        "    return Xdly, ydly\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAD_TYXvJBRc"
      },
      "source": [
        "Now fit an linear delayed model with `dly=6` additional delay lags.  That is,\n",
        "* Create delayed data `Xdly,ydly=create_dly_data(X,y,dly=6)`\n",
        "* Split the data into training and test as before\n",
        "* Fit the model on the training data\n",
        "* Measure the `R^2` score on the test data\n",
        "\n",
        "If you did this correctly, you should get a new `R^2` score around 0.69.  This is significantly better than the memoryless models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ihn__lOZJBRc"
      },
      "outputs": [],
      "source": [
        "# Create delayed data with dly=6\n",
        "Xdly, ydly = create_dly_data(X, y, dly=6)\n",
        "\n",
        "# Split into training and test sets\n",
        "Xtr, Xts, ytr, yts = train_test_split(Xdly, ydly, test_size=0.33, random_state=0)\n",
        "\n",
        "# Fit linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(Xtr, ytr)\n",
        "\n",
        "# Predict and compute R^2 score\n",
        "yhat = model.predict(Xts)\n",
        "rsq = r2_score(yts, yhat)\n",
        "\n",
        "print(\"R^2 with delayed model (dly=6):\", rsq)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PD6bktyJBRc"
      },
      "source": [
        "Plot the predicted vs. true values as before. You should visually see a better fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOKf5rmAJBRd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "for i in range(y.shape[1]):   # 两个输出变量\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.scatter(yts[:, i], yhat[:, i], alpha=0.5)\n",
        "    plt.xlabel(\"True y{}\".format(i))\n",
        "    plt.ylabel(\"Predicted y{}\".format(i))\n",
        "    plt.plot([yts[:, i].min(), yts[:, i].max()],\n",
        "             [yts[:, i].min(), yts[:, i].max()],\n",
        "             'r--')   # 参考对角线\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdgj0CiNJBRd"
      },
      "source": [
        "*Note*:  Fitting an FIR model with the above method is very inefficient when the number of delays, `dly` is large.  In the above method, the number of columns of `X` grows from `p` to `(dly+1)*p` and the computations become expensive with `dly` is large.  We will describe a much faster way to fit such models using gradient descent when we talk about convolutional neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao-Q2lAeJBRd"
      },
      "source": [
        "## Selecting the Optimal Delay via Model Order Selection\n",
        "\n",
        "In the previous example, we fixed `dly=6`.  We can now select the optimal delay using model order selection.  Since we have a large number of data samples, it turns out that the optimal model order uses a very high delay.  Using the above fitting method, the computations take too long.  So, to simplify the lab, we will first just pretent that we have a very limited data set.\n",
        "\n",
        "Compute `Xred` and `yred` by taking the first `nred=6000` samples of the data `X` and `y`.  This is about 10% of the overall data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV4z61kHJBRd"
      },
      "outputs": [],
      "source": [
        "nred = 6000\n",
        "\n",
        "# TODO\n",
        "Xred = X[:nred, :]\n",
        "yred = y[:nred, :]\n",
        "\n",
        "print(\"Reduced data shapes:\", Xred.shape, yred.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g19bEtYJBRd"
      },
      "source": [
        "Now complete the following code to implement K-fold cross validation with `nfold=5` and values of delays `dtest = [0,1,...,dmax]`.  \n",
        "\n",
        "The code also includes a progress bar using the `tqdm` package.  This is very useful when you have a long computation.\n",
        "\n",
        "Note:  Some students appeared to use the `mse` metric (i.e. RSS per sample) instead of `R^2`.  That is fine.  For the solution, I have computed both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neZ--RHrJBRd"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "import tqdm.notebook\n",
        "\n",
        "nfold = 5     # number of folds\n",
        "dmax = 15     # maximum number of delays\n",
        "\n",
        "kf = model_selection.KFold(n_splits=nfold, shuffle=True, random_state=0)\n",
        "\n",
        "# Model orders to be tested\n",
        "dtest = np.arange(0, dmax+1)\n",
        "nd = len(dtest)\n",
        "\n",
        "# Initialize Rsq matrix: rows=folds, cols=model orders\n",
        "Rsq = np.zeros((nfold, nd))\n",
        "\n",
        "# Create progress bar\n",
        "pbar = tqdm.notebook.tqdm(total=nd*nfold, initial=0,\n",
        "                          unit='fits', unit_divisor=nd,\n",
        "                          desc='Model order test')\n",
        "\n",
        "for id, d in enumerate(dtest):\n",
        "    # TODO: Create delayed data\n",
        "    Xdly, ydly = create_dly_data(Xred, yred, d)\n",
        "\n",
        "    # Loop over folds\n",
        "    for ifold, Ind in enumerate(kf.split(Xdly)):\n",
        "        Itr, Its = Ind   # training and test indices\n",
        "\n",
        "        # TODO: Split data\n",
        "        Xtr, Xts = Xdly[Itr,:], Xdly[Its,:]\n",
        "        ytr, yts = ydly[Itr,:], ydly[Its,:]\n",
        "\n",
        "        # TODO: Fit linear regression\n",
        "        model = LinearRegression()\n",
        "        model.fit(Xtr, ytr)\n",
        "\n",
        "        # TODO: Predict and compute R^2\n",
        "        yhat = model.predict(Xts)\n",
        "        Rsq[ifold, id] = r2_score(yts, yhat)\n",
        "\n",
        "        pbar.update(1)\n",
        "\n",
        "pbar.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p-jXSjlJBRd"
      },
      "source": [
        "Compute the mean and standard error of the `R^2` values as a function of the model order `d`.  Use a `plt.errorbar` plot.  Label your axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYTCZ7OcJBRd"
      },
      "outputs": [],
      "source": [
        "# Compute mean and standard error\n",
        "Rsq_mean = np.mean(Rsq, axis=0)\n",
        "Rsq_se = np.std(Rsq, axis=0) / np.sqrt(Rsq.shape[0])\n",
        "\n",
        "# Plot with error bars\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.errorbar(dtest, Rsq_mean, yerr=Rsq_se, fmt='-o', capsize=5)\n",
        "plt.xlabel(\"Model order (dly)\")\n",
        "plt.ylabel(\"R^2 score\")\n",
        "plt.title(\"Model order selection\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5sRiHYIJBRe"
      },
      "source": [
        "Find the optimal order `d` with the normal rule (i.e. highest test `R^2`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ponZFi-eJBRe"
      },
      "outputs": [],
      "source": [
        "# Find optimal order d with normal rule (highest mean R^2)\n",
        "best_d = dtest[np.argmax(Rsq_mean)]\n",
        "best_r2 = np.max(Rsq_mean)\n",
        "\n",
        "print(\"Optimal delay order (normal rule):\", best_d)\n",
        "print(\"Corresponding mean R^2:\", best_r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUpdGVpUJBRe"
      },
      "source": [
        "Now find the optimal model order via the one SE rule (i.e. highest test `R^2` within on SE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltKI4JxVJBRe"
      },
      "outputs": [],
      "source": [
        "# One standard error rule\n",
        "best_mean = np.max(Rsq_mean)\n",
        "best_idx = np.argmax(Rsq_mean)\n",
        "threshold = best_mean - Rsq_se[best_idx]\n",
        "\n",
        "# 选择满足 Rsq_mean >= threshold 的最小 d\n",
        "candidate_idx = np.where(Rsq_mean >= threshold)[0]\n",
        "best_d_se = dtest[np.min(candidate_idx)]\n",
        "\n",
        "print(\"Optimal delay order (1-SE rule):\", best_d_se)\n",
        "print(\"Corresponding mean R^2:\", Rsq_mean[np.min(candidate_idx)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftPac9D7JBRe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}